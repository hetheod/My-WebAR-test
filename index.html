<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Template Matching with Three.js</title>
    <style>
        body { margin: 0; overflow: hidden; }
        video { display: none; }
    </style>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/GLTFLoader.js"></script>
</head>
<body>
    <video id="video" width="640" height="480" autoplay></video>
    <canvas id="canvas"></canvas>
    <script>
        // Set up video capture
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');

        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                video.srcObject = stream;
                video.play();
            });

        // Set up Three.js
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
        const renderer = new THREE.WebGLRenderer();
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Add a light source
        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(1, 1, 1).normalize();
        scene.add(light);

        // Load the 3D model
        const loader = new THREE.GLTFLoader();
        let model;
        loader.load('./assets/city.glb', gltf => {
            model = gltf.scene;
            model.scale.set(0.01, 0.01, 0.01);
            scene.add(model);
        });

        camera.position.z = 5;

        // Template matching logic
        const targetImage = new Image();
        targetImage.src = './assets/Tracking_Image_Mitja.jpg'; // Your target image

        function compareImages(videoFrame, targetImage, threshold = 0.1) {
            context.drawImage(videoFrame, 0, 0, canvas.width, canvas.height);
            const frameData = context.getImageData(0, 0, canvas.width, canvas.height);

            context.drawImage(targetImage, 0, 0, targetImage.width, targetImage.height);
            const targetData = context.getImageData(0, 0, targetImage.width, targetImage.height);

            let diff = 0;
            for (let i = 0; i < frameData.data.length; i += 4) {
                const rDiff = Math.abs(frameData.data[i] - targetData.data[i]);
                const gDiff = Math.abs(frameData.data[i + 1] - targetData.data[i + 1]);
                const bDiff = Math.abs(frameData.data[i + 2] - targetData.data[i + 2]);
                diff += rDiff + gDiff + bDiff;
            }

            return (diff / frameData.data.length < threshold);
        }

        function processFrame() {
            if (compareImages(video, targetImage)) {
                console.log('Image detected!');
                if (model) {
                    // Position the model in the scene when the image is detected
                    model.position.set(0, 0, -5);
                }
            } else {
                if (model) {
                    // Hide the model if the image is not detected
                    model.position.set(0, 0, -100); // Move the model out of view
                }
            }
            requestAnimationFrame(processFrame);
        }

        targetImage.onload = () => {
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            processFrame();
        };

        function animate() {
            requestAnimationFrame(animate);
            renderer.render(scene, camera);
        }

        animate();
    </script>
</body>
</html>
