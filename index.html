<!DOCTYPE html>
<html lang="en">
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>Image Tracking with Three.js and OpenCV.js</title>
    <style>
      body {
        margin: 0;
        overflow: hidden;
      }
      canvas {
        display: block;
      }
    </style>
    <!-- Include Three.js and OpenCV.js -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script async src="https://docs.opencv.org/3.4.0/opencv.js"></script>
  </head>
  <body>
    <video id="video" autoplay playsinline style="display:none;"></video>
    <script>
      let scene, camera, renderer, model, video, canvas, ctx;
      let targetImage = null;
      let videoReady = false;
      let trackingImageDetected = false;
      let detector, keypoints1, descriptors1;

      function init() {
        // Three.js setup
        scene = new THREE.Scene();

        camera = new THREE.PerspectiveCamera(70, window.innerWidth / window.innerHeight, 0.1, 100);
        camera.position.z = 3;

        renderer = new THREE.WebGLRenderer({ alpha: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        document.body.appendChild(renderer.domElement);

        // Load 3D model (city)
        const loader = new THREE.GLTFLoader();
        loader.load('./assets/city.glb', (gltf) => {
          model = gltf.scene;
          model.scale.set(0.01, 0.01, 0.01);
          model.visible = false;
          scene.add(model);
        });

        // OpenCV.js setup
        video = document.createElement('video');
        video.setAttribute('autoplay', true);
        video.setAttribute('playsinline', true);
        video.style.display = 'none';
        document.body.appendChild(video);

        // Canvas for OpenCV image tracking
        canvas = document.createElement('canvas');
        ctx = canvas.getContext('2d');
        canvas.width = window.innerWidth;
        canvas.height = window.innerHeight;

        // Get camera feed
        navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
          video.srcObject = stream;
          video.play();
          videoReady = true;
        });

        // Load the target image for tracking
        const img = new Image();
        img.src = './assets/targets/targetImage.jpg'; // The image to track
        img.onload = function () {
          targetImage = cv.imread(img); // Load target image into OpenCV
          initializeFeatureDetection();
        };

        animate();
      }

      // Initialize ORB feature detector for the target image
      function initializeFeatureDetection() {
        detector = new cv.ORB(); // ORB detector
        keypoints1 = new cv.KeyPointVector();
        descriptors1 = new cv.Mat();
        detector.detectAndCompute(targetImage, new cv.Mat(), keypoints1, descriptors1);
      }

      // OpenCV image detection and tracking logic
      function detectImage() {
        if (!videoReady || !targetImage) return false;

        // Capture video frame into the canvas
        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        const src = cv.imread(canvas); // Read video frame as an OpenCV Mat

        // Image recognition using OpenCV (ORB/SIFT-like feature matching)
        let keypoints2 = new cv.KeyPointVector();
        let descriptors2 = new cv.Mat();
        detector.detectAndCompute(src, new cv.Mat(), keypoints2, descriptors2);

        let matcher = new cv.BFMatcher(cv.NORM_HAMMING, true);
        let matches = new cv.DMatchVector();
        matcher.match(descriptors1, descriptors2, matches);

        // Check if enough matches found to consider the image detected
        if (matches.size() > 10) {
          trackingImageDetected = true;
          return true;
        } else {
          trackingImageDetected = false;
          return false;
        }
      }

      function animate() {
        requestAnimationFrame(animate);

        if (detectImage()) {
          // If image is detected, update the 3D model's position and visibility
          model.visible = true;

          // In a real case, calculate where to place the model based on keypoints or homography
          model.position.set(0, 0, 0); // Simplified: Set model's position relative to the image detection

          // Optionally, calculate homography here and adjust model position/rotation
        } else {
          model.visible = false; // Hide model if image is not detected
        }

        renderer.render(scene, camera);
      }

      window.onload = init;
    </script>
  </body>
</html>
